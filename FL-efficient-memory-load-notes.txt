mem-efficient-load
sparsemap tensor exp notes

nov 9 2024

branch: mem-efficient-load

the code is at rwkv/sparse_exp/sparsemap.py 
    this is the main implementation. b/c tensor is difficult to wrap, so I ust write a bunch of functions, e.g. 
    to create a sparasemap tensor out of a disk file, or to convert a dense tensor to a disk file
    also "remap" --- maks/unmask some rows 

then I added exp code to rwkv/model.py and run.py (for pipeline)
deleting unused weights (e.g. CLS) and trnasofmr some dense tensors to sparsaemap 

mostly did exp with 0.1B

HIGH LEVEL OBS: 
pytorch itself takes 200MB (likely diffciult to save) 
tokenizer takes 300MB (!) and is used for both encodign and decoding (so cannot easily free it)
    for tiny model, something needs to be done with it. Otherwise, saving is minor.

delete unused tensors (then gc.collect()) can save memory. but has to be careful with linginering refernecs. otherwise no saving

THOUGHTS ON sparasemap tensors 

-it's functioning. to free certain rows, no need to unmap. just map that row (precisly, the residing page) to anon mkapping, kernel will 
free thie phsy memory immediately (gratt) 

    exp code is under sparse-exp/test-XXX

MJAOAR inefficeincy

- see above. tokenizer, pytorch. -- 600MB

about sparsemap tensor
- efficienct bottleneck 1. mapping must be done in page granulaty. therefmore the "page" sparsity is lower than the row sparsity. bad
    perhaps colocate the rows (seems the only way) 

- bottleneck 2. ffn.value is col baed. likely the activation map (the saprse one) must be transposed before muliplying with ffn.value
    therefore, it's more like the the ggml tensor format (always transposed)

#################

.1b, with cls, with mlp

Before load model - Process memory: 200.03 MB, System memory: 2993.05 MB / 8053.72 MB
After load model - Process memory: 628.97 MB, System memory: 3443.03 MB / 8053.72 MB
After gc - Process memory: 628.97 MB, System memory: 3449.36 MB / 8053.72 MB
Before deleting head.weight - Process memory: 628.97 MB, System memory: 3449.36 MB / 8053.72 MB
will delete: head.weight, shape: torch.Size([65536, 768]), size: 98304.00 KB
After deleting head.weight - Process memory: 533.62 MB, System memory: 3360.75 MB / 8053.72 MB


del orghead
del w['head.weight']
# can free ~90MB
4444 Before deleting head.weight - Process memory: 906.09 MB, System memory: 3229.97 MB / 8053.72 MB
will delete: head.weight, shape: torch.Size([768, 65536]), size: 98304.00 KB
4444  After deleting head.weight - Process memory: 810.11 MB, System memory: 3135.97 MB / 8053.72 MB


# ... loading torch will consume 200MB....
import torch
import torch.nn as nn
from torch.nn import functional as F
print_memory_usage("after load torch")      # 194MB




before del emb - Process memory: 625.92 MB, System memory: 3626.39 MB / 8053.72 MB
After del emb - Process memory: 531.80 MB, System memory: 3623.48 MB / 8053.72 MB